## Put your trainer args here
trainer:
  deterministic: warn
  devices: auto 
  accelerator: auto
  precision: 32
  max_epochs: 400
  accumulate_grad_batches: 1 # Makes effective batch size = N * batch_size
  num_sanity_val_steps: 1 
  gradient_clip_val: 10
  gradient_clip_algorithm: value
 # profiler: simple

  limit_train_batches: 2
  limit_val_batches: 1
  limit_predict_batches: 1
