## Put your trainer args here
trainer:
  deterministic: warn
  devices: auto 
  accelerator: auto
  precision: 32
  max_epochs: 100
  accumulate_grad_batches: 1 # Makes effective batch size = N * batch_size
  num_sanity_val_steps: 1 
  gradient_clip_val: 10
  gradient_clip_algorithm: value
  profiler: simple

  val_check_interval: 5