## Put your trainer args here
trainer:
  deterministic: warn
  devices: auto 
  accelerator: auto
  precision: 32
  max_epochs: 200
  accumulate_grad_batches: 1 # Makes effective batch size = N * batch_size
  num_sanity_val_steps: 1 
  gradient_clip_val: 5.0
  gradient_clip_algorithm: norm
  #val_check_interval: 5000
  check_val_every_n_epoch: 10
 # profiler: simple

  #limit_train_batches: 0.1
  limit_val_batches: 4
  limit_predict_batches: 2
